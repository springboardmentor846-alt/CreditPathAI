{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4126665-0813-46d4-b159-73284c4b37a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/keyur/Desktop/Infosys%20Internship/mlruns/965005163601104093', creation_time=1762936466055, experiment_id='965005163601104093', last_update_time=1762936466055, lifecycle_stage='active', name='CreditPathAI_Loan_Default_Prediction', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. INSTALLATION AND IMPORTS\n",
    "# !pip install pandas numpy seaborn scikit-learn xgboost lightgbm mlflow sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import sqlite3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"CreditPathAI_Loan_Default_Prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38717fb3-98ed-4a8d-92ab-3bd13eae0ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (255347, 18)\n",
      "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "0  I38PQUQS96   56   85994       50587          520              80   \n",
      "1  HPSK72WA7R   69   50432      124440          458              15   \n",
      "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
      "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
      "4  EY08JDHTZP   60   20437        9139          633               8   \n",
      "\n",
      "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
      "0               4         15.23        36      0.44   Bachelor's   \n",
      "1               1          4.81        60      0.68     Master's   \n",
      "2               3         21.17        24      0.31     Master's   \n",
      "3               3          7.07        24      0.23  High School   \n",
      "4               4          6.51        48      0.73   Bachelor's   \n",
      "\n",
      "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
      "0      Full-time      Divorced         Yes           Yes       Other   \n",
      "1      Full-time       Married          No            No       Other   \n",
      "2     Unemployed      Divorced         Yes           Yes        Auto   \n",
      "3      Full-time       Married          No            No    Business   \n",
      "4     Unemployed      Divorced          No           Yes        Auto   \n",
      "\n",
      "  HasCoSigner  Default  \n",
      "0         Yes        0  \n",
      "1         Yes        0  \n",
      "2          No        1  \n",
      "3          No        0  \n",
      "4          No        0  \n"
     ]
    }
   ],
   "source": [
    "# 2. DATA INGESTION\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load and prepare the loan default dataset from a CSV file\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "\n",
    "file_path = \"Loan_default.csv\"\n",
    "df = load_data(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217cffdd-775e-4832-b522-af5e81d1eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPLORATORY DATA ANALYSIS ===\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 255347 entries, 0 to 255346\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   LoanID          255347 non-null  object \n",
      " 1   Age             255347 non-null  int64  \n",
      " 2   Income          255347 non-null  int64  \n",
      " 3   LoanAmount      255347 non-null  int64  \n",
      " 4   CreditScore     255347 non-null  int64  \n",
      " 5   MonthsEmployed  255347 non-null  int64  \n",
      " 6   NumCreditLines  255347 non-null  int64  \n",
      " 7   InterestRate    255347 non-null  float64\n",
      " 8   LoanTerm        255347 non-null  int64  \n",
      " 9   DTIRatio        255347 non-null  float64\n",
      " 10  Education       255347 non-null  object \n",
      " 11  EmploymentType  255347 non-null  object \n",
      " 12  MaritalStatus   255347 non-null  object \n",
      " 13  HasMortgage     255347 non-null  object \n",
      " 14  HasDependents   255347 non-null  object \n",
      " 15  LoanPurpose     255347 non-null  object \n",
      " 16  HasCoSigner     255347 non-null  object \n",
      " 17  Default         255347 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 35.1+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "                 Age         Income     LoanAmount    CreditScore  \\\n",
      "count  255347.000000  255347.000000  255347.000000  255347.000000   \n",
      "mean       43.498306   82499.304597  127578.865512     574.264346   \n",
      "std        14.990258   38963.013729   70840.706142     158.903867   \n",
      "min        18.000000   15000.000000    5000.000000     300.000000   \n",
      "25%        31.000000   48825.500000   66156.000000     437.000000   \n",
      "50%        43.000000   82466.000000  127556.000000     574.000000   \n",
      "75%        56.000000  116219.000000  188985.000000     712.000000   \n",
      "max        69.000000  149999.000000  249999.000000     849.000000   \n",
      "\n",
      "       MonthsEmployed  NumCreditLines   InterestRate       LoanTerm  \\\n",
      "count   255347.000000   255347.000000  255347.000000  255347.000000   \n",
      "mean        59.541976        2.501036      13.492773      36.025894   \n",
      "std         34.643376        1.117018       6.636443      16.969330   \n",
      "min          0.000000        1.000000       2.000000      12.000000   \n",
      "25%         30.000000        2.000000       7.770000      24.000000   \n",
      "50%         60.000000        2.000000      13.460000      36.000000   \n",
      "75%         90.000000        3.000000      19.250000      48.000000   \n",
      "max        119.000000        4.000000      25.000000      60.000000   \n",
      "\n",
      "            DTIRatio        Default  \n",
      "count  255347.000000  255347.000000  \n",
      "mean        0.500212       0.116128  \n",
      "std         0.230917       0.320379  \n",
      "min         0.100000       0.000000  \n",
      "25%         0.300000       0.000000  \n",
      "50%         0.500000       0.000000  \n",
      "75%         0.700000       0.000000  \n",
      "max         0.900000       1.000000  \n",
      "\n",
      "Missing Values:\n",
      "LoanID            0\n",
      "Age               0\n",
      "Income            0\n",
      "LoanAmount        0\n",
      "CreditScore       0\n",
      "MonthsEmployed    0\n",
      "NumCreditLines    0\n",
      "InterestRate      0\n",
      "LoanTerm          0\n",
      "DTIRatio          0\n",
      "Education         0\n",
      "EmploymentType    0\n",
      "MaritalStatus     0\n",
      "HasMortgage       0\n",
      "HasDependents     0\n",
      "LoanPurpose       0\n",
      "HasCoSigner       0\n",
      "Default           0\n",
      "dtype: int64\n",
      "\n",
      "Target Distribution:\n",
      "Default\n",
      "0    225694\n",
      "1     29653\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. EXPLORATORY DATA ANALYSIS\n",
    "def perform_eda(df):\n",
    "    \"\"\"Quick EDA without visualizations\"\"\"\n",
    "    print(\"=== EXPLORATORY DATA ANALYSIS ===\")\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nTarget Distribution:\")\n",
    "    print(df['Default'].value_counts())\n",
    "\n",
    "perform_eda(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8931861c-81ef-41e5-aa3e-60c4335dfda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE ENGINEERING ===\n",
      "Features: 20 | Records: 255347\n"
     ]
    }
   ],
   "source": [
    "# 4. FEATURE ENGINEERING\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering and preprocessing\"\"\"\n",
    "    print(\"=== FEATURE ENGINEERING ===\")\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    df_processed['LoanToIncome'] = df_processed['LoanAmount'] / df_processed['Income']\n",
    "    df_processed['MonthlyPayment'] = (\n",
    "        (df_processed['LoanAmount'] *\n",
    "         (df_processed['InterestRate']/100/12) *\n",
    "         (1 + df_processed['InterestRate']/100/12)**df_processed['LoanTerm']) /\n",
    "        ((1 + df_processed['InterestRate']/100/12)**df_processed['LoanTerm'] - 1)\n",
    "    )\n",
    "    df_processed['PaymentToIncome'] = df_processed['MonthlyPayment'] / (df_processed['Income']/12)\n",
    "    df_processed['CreditUtilization'] = df_processed['LoanAmount'] / df_processed['CreditScore']\n",
    "    \n",
    "    categorical_cols = ['Education', 'EmploymentType', 'MaritalStatus', \n",
    "                        'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col + '_encoded'] = le.fit_transform(df_processed[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    feature_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', \n",
    "                    'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', \n",
    "                    'LoanToIncome', 'MonthlyPayment', 'PaymentToIncome', 'CreditUtilization'] + \\\n",
    "                   [col + '_encoded' for col in categorical_cols]\n",
    "    \n",
    "    X = df_processed[feature_cols]\n",
    "    y = df_processed['Default']\n",
    "    \n",
    "    print(f\"Features: {X.shape[1]} | Records: {X.shape[0]}\")\n",
    "    return X, y, df_processed, label_encoders\n",
    "\n",
    "X, y, df_processed, label_encoders = feature_engineering(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6039ce2e-b7bd-41dd-a7f1-244b0547d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 5. DATA PREPROCESSING\n",
    "def preprocess_data(X, y):\n",
    "    \"\"\"Split and scale data\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Data preprocessed successfully!\")\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler = preprocess_data(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418fc820-b0a7-460c-9f8f-fd906a6d0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression RESULTS ===\n",
      "AUC-ROC Score: 0.7594\n",
      "Confusion Matrix:\n",
      "[[67329   380]\n",
      " [ 8313   583]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     67709\n",
      "           1       0.61      0.07      0.12      8896\n",
      "\n",
      "    accuracy                           0.89     76605\n",
      "   macro avg       0.75      0.53      0.53     76605\n",
      "weighted avg       0.86      0.89      0.84     76605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 18:37:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost RESULTS ===\n",
      "AUC-ROC Score: 0.7556\n",
      "Confusion Matrix:\n",
      "[[67273   436]\n",
      " [ 8263   633]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     67709\n",
      "           1       0.59      0.07      0.13      8896\n",
      "\n",
      "    accuracy                           0.89     76605\n",
      "   macro avg       0.74      0.53      0.53     76605\n",
      "weighted avg       0.86      0.89      0.84     76605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 18:38:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20757, number of negative: 157985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2335\n",
      "[LightGBM] [Info] Number of data points in the train set: 178742, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116128 -> initscore=-2.029617\n",
      "[LightGBM] [Info] Start training from score -2.029617\n",
      "\n",
      "=== LightGBM RESULTS ===\n",
      "AUC-ROC Score: 0.7576\n",
      "Confusion Matrix:\n",
      "[[67303   406]\n",
      " [ 8280   616]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     67709\n",
      "           1       0.60      0.07      0.12      8896\n",
      "\n",
      "    accuracy                           0.89     76605\n",
      "   macro avg       0.75      0.53      0.53     76605\n",
      "weighted avg       0.86      0.89      0.84     76605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 18:38:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# 6. MODEL TRAINING AND EVALUATION (NO ROC CURVES)\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n=== {model_name} RESULTS ===\")\n",
    "    print(f\"AUC-ROC Score: {auc_roc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    return auc_roc\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Logistic Regression\n",
    "with mlflow.start_run(run_name=\"Logistic_Regression\"):\n",
    "    lr_model = LogisticRegression(random_state=42)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    models['Logistic Regression'] = lr_model\n",
    "    auc = evaluate_model(lr_model, X_test, y_test, \"Logistic Regression\")\n",
    "    results['Logistic Regression'] = auc\n",
    "    mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.sklearn.log_model(lr_model, name=\"logistic_regression_model\")\n",
    "\n",
    "# XGBoost\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    xgb_model = xgb.XGBClassifier(random_state=42, n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    models['XGBoost'] = xgb_model\n",
    "    auc = evaluate_model(xgb_model, X_test, y_test, \"XGBoost\")\n",
    "    results['XGBoost'] = auc\n",
    "    mlflow.log_param(\"model\", \"XGBoost\")\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.xgboost.log_model(xgb_model, name=\"xgboost_model\")\n",
    "\n",
    "# LightGBM\n",
    "with mlflow.start_run(run_name=\"LightGBM\"):\n",
    "    lgb_model = lgb.LGBMClassifier(random_state=42, n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    models['LightGBM'] = lgb_model\n",
    "    auc = evaluate_model(lgb_model, X_test, y_test, \"LightGBM\")\n",
    "    results['LightGBM'] = auc\n",
    "    mlflow.log_param(\"model\", \"LightGBM\")\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.lightgbm.log_model(lgb_model, name=\"lightgbm_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e0885c-5d14-4537-9c0d-8dcfd8847ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL COMPARISON ===\n",
      "                 Model   AUC-ROC\n",
      "0  Logistic Regression  0.759427\n",
      "2             LightGBM  0.757560\n",
      "1              XGBoost  0.755599\n"
     ]
    }
   ],
   "source": [
    "# 7. MODEL COMPARISON (TEXT ONLY)\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "model_comparison = pd.DataFrame({'Model': results.keys(), 'AUC-ROC': results.values()}).sort_values('AUC-ROC', ascending=False)\n",
    "print(model_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15de7cbb-192f-472f-b93a-730eab1caa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Features - XGBoost\n",
      "                   Feature  Importance\n",
      "9             LoanToIncome    0.192613\n",
      "0                      Age    0.159368\n",
      "6             InterestRate    0.093816\n",
      "4           MonthsEmployed    0.059938\n",
      "17   HasDependents_encoded    0.058322\n",
      "19     HasCoSigner_encoded    0.052618\n",
      "14  EmploymentType_encoded    0.048558\n",
      "16     HasMortgage_encoded    0.037627\n",
      "13       Education_encoded    0.032721\n",
      "5           NumCreditLines    0.031935\n",
      "\n",
      "Top 10 Features - LightGBM\n",
      "              Feature  Importance\n",
      "6        InterestRate         394\n",
      "4      MonthsEmployed         357\n",
      "0                 Age         296\n",
      "3         CreditScore         233\n",
      "1              Income         222\n",
      "9        LoanToIncome         210\n",
      "8            DTIRatio         175\n",
      "12  CreditUtilization         156\n",
      "11    PaymentToIncome         121\n",
      "2          LoanAmount         118\n"
     ]
    }
   ],
   "source": [
    "# 8. FEATURE IMPORTANCE (OPTIONAL DISPLAY)\n",
    "def show_top_features(model, feature_names, model_name):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        imp = pd.DataFrame({'Feature': feature_names, 'Importance': model.feature_importances_})\n",
    "        imp = imp.sort_values('Importance', ascending=False).head(10)\n",
    "        print(f\"\\nTop 10 Features - {model_name}\")\n",
    "        print(imp)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name != 'Logistic Regression':\n",
    "        show_top_features(model, X.columns.tolist(), name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733a4247-aa1f-43fe-8ad3-2d2ca3073af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter LoanID to generate recommendations:  GX5YQOGROM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RECOMMENDATION FOR LoanID: GX5YQOGROM ===\n",
      "Default Probability: 2.73%\n",
      "Risk Level: Low Risk\n",
      "Recommended Action: Monitor regularly\n"
     ]
    }
   ],
   "source": [
    "# 9. RECOMMENDATIONS (INPUT BASED)\n",
    "def generate_recommendations(model, scaler, sample_data):\n",
    "    \"\"\"Generate risk-based recovery recommendations\"\"\"\n",
    "    scaled = scaler.transform(sample_data.reshape(1, -1))\n",
    "    prob = model.predict_proba(scaled)[0, 1]\n",
    "    if prob < 0.3:\n",
    "        level, action = \"Low Risk\", \"Monitor regularly\"\n",
    "    elif prob < 0.7:\n",
    "        level, action = \"Medium Risk\", \"Contact borrower, offer payment plan options\"\n",
    "    else:\n",
    "        level, action = \"High Risk\", \"Escalate to collections, consider restructuring\"\n",
    "    return prob, level, action\n",
    "\n",
    "def get_recommendations_by_loanid(df, X, model, scaler):\n",
    "    \"\"\"Ask user for LoanID and generate recommendations\"\"\"\n",
    "    loan_id = input(\"\\nEnter LoanID to generate recommendations: \").strip()\n",
    "    if loan_id not in df['LoanID'].astype(str).values:\n",
    "        print(\"LoanID not found.\")\n",
    "        return\n",
    "    idx = df[df['LoanID'].astype(str) == loan_id].index[0]\n",
    "    data = X.iloc[idx].values\n",
    "    prob, level, action = generate_recommendations(model, scaler, data)\n",
    "    print(f\"\\n=== RECOMMENDATION FOR LoanID: {loan_id} ===\")\n",
    "    print(f\"Default Probability: {prob:.2%}\")\n",
    "    print(f\"Risk Level: {level}\")\n",
    "    print(f\"Recommended Action: {action}\")\n",
    "\n",
    "best_model = models[model_comparison.iloc[0]['Model']]\n",
    "get_recommendations_by_loanid(df, X, best_model, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee740dfd-b2ca-4734-91d6-ea8ec7098d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data stored successfully in creditpathai.db\n"
     ]
    }
   ],
   "source": [
    "# 10. STORE DATA IN SQLITE\n",
    "def store_data_sqlite(df, db_name='creditpathai.db'):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    df.to_sql('loan_data', conn, if_exists='replace', index=False)\n",
    "    pd.DataFrame({'Model': results.keys(), 'AUC_ROC': results.values(), 'Timestamp': [pd.Timestamp.now()] * len(results)}\n",
    "                 ).to_sql('model_results', conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    print(f\"\\nData stored successfully in {db_name}\")\n",
    "\n",
    "store_data_sqlite(df_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd88511b-b308-41b7-8340-6138d0467490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CREDITPATHAI - PROJECT SUMMARY\n",
      "==================================================\n",
      "Dataset: (255347, 18), Features: 20\n",
      "Default Rate: 11.61%\n",
      "Best Model: Logistic Regression (AUC: 0.7594)\n"
     ]
    }
   ],
   "source": [
    "# 11. SUMMARY\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CREDITPATHAI - PROJECT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset: {df.shape}, Features: {X.shape[1]}\")\n",
    "print(f\"Default Rate: {df['Default'].mean():.2%}\")\n",
    "print(f\"Best Model: {model_comparison.iloc[0]['Model']} (AUC: {model_comparison.iloc[0]['AUC-ROC']:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
