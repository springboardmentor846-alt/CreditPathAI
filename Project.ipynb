{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4126665-0813-46d4-b159-73284c4b37a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/keyur/Desktop/Infosys%20Internship/mlruns/585164079611077161', creation_time=1763211325602, experiment_id='585164079611077161', last_update_time=1763211325602, lifecycle_stage='active', name='CreditPathAI_Loan_Default_Prediction', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. INSTALLATION AND IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import sqlite3\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"CreditPathAI_Loan_Default_Prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38717fb3-98ed-4a8d-92ab-3bd13eae0ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (255347, 18)\n",
      "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "0  I38PQUQS96   56   85994       50587          520              80   \n",
      "1  HPSK72WA7R   69   50432      124440          458              15   \n",
      "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
      "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
      "4  EY08JDHTZP   60   20437        9139          633               8   \n",
      "\n",
      "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
      "0               4         15.23        36      0.44   Bachelor's   \n",
      "1               1          4.81        60      0.68     Master's   \n",
      "2               3         21.17        24      0.31     Master's   \n",
      "3               3          7.07        24      0.23  High School   \n",
      "4               4          6.51        48      0.73   Bachelor's   \n",
      "\n",
      "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
      "0      Full-time      Divorced         Yes           Yes       Other   \n",
      "1      Full-time       Married          No            No       Other   \n",
      "2     Unemployed      Divorced         Yes           Yes        Auto   \n",
      "3      Full-time       Married          No            No    Business   \n",
      "4     Unemployed      Divorced          No           Yes        Auto   \n",
      "\n",
      "  HasCoSigner  Default  \n",
      "0         Yes        0  \n",
      "1         Yes        0  \n",
      "2          No        1  \n",
      "3          No        0  \n",
      "4          No        0  \n"
     ]
    }
   ],
   "source": [
    "# 2. DATA INGESTION\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load and prepare the loan default dataset from a CSV file\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "\n",
    "file_path = \"Loan_default.csv\"\n",
    "df = load_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217cffdd-775e-4832-b522-af5e81d1eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPLORATORY DATA ANALYSIS ===\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 255347 entries, 0 to 255346\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   LoanID          255347 non-null  object \n",
      " 1   Age             255347 non-null  int64  \n",
      " 2   Income          255347 non-null  int64  \n",
      " 3   LoanAmount      255347 non-null  int64  \n",
      " 4   CreditScore     255347 non-null  int64  \n",
      " 5   MonthsEmployed  255347 non-null  int64  \n",
      " 6   NumCreditLines  255347 non-null  int64  \n",
      " 7   InterestRate    255347 non-null  float64\n",
      " 8   LoanTerm        255347 non-null  int64  \n",
      " 9   DTIRatio        255347 non-null  float64\n",
      " 10  Education       255347 non-null  object \n",
      " 11  EmploymentType  255347 non-null  object \n",
      " 12  MaritalStatus   255347 non-null  object \n",
      " 13  HasMortgage     255347 non-null  object \n",
      " 14  HasDependents   255347 non-null  object \n",
      " 15  LoanPurpose     255347 non-null  object \n",
      " 16  HasCoSigner     255347 non-null  object \n",
      " 17  Default         255347 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 35.1+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "                 Age         Income     LoanAmount    CreditScore  \\\n",
      "count  255347.000000  255347.000000  255347.000000  255347.000000   \n",
      "mean       43.498306   82499.304597  127578.865512     574.264346   \n",
      "std        14.990258   38963.013729   70840.706142     158.903867   \n",
      "min        18.000000   15000.000000    5000.000000     300.000000   \n",
      "25%        31.000000   48825.500000   66156.000000     437.000000   \n",
      "50%        43.000000   82466.000000  127556.000000     574.000000   \n",
      "75%        56.000000  116219.000000  188985.000000     712.000000   \n",
      "max        69.000000  149999.000000  249999.000000     849.000000   \n",
      "\n",
      "       MonthsEmployed  NumCreditLines   InterestRate       LoanTerm  \\\n",
      "count   255347.000000   255347.000000  255347.000000  255347.000000   \n",
      "mean        59.541976        2.501036      13.492773      36.025894   \n",
      "std         34.643376        1.117018       6.636443      16.969330   \n",
      "min          0.000000        1.000000       2.000000      12.000000   \n",
      "25%         30.000000        2.000000       7.770000      24.000000   \n",
      "50%         60.000000        2.000000      13.460000      36.000000   \n",
      "75%         90.000000        3.000000      19.250000      48.000000   \n",
      "max        119.000000        4.000000      25.000000      60.000000   \n",
      "\n",
      "            DTIRatio        Default  \n",
      "count  255347.000000  255347.000000  \n",
      "mean        0.500212       0.116128  \n",
      "std         0.230917       0.320379  \n",
      "min         0.100000       0.000000  \n",
      "25%         0.300000       0.000000  \n",
      "50%         0.500000       0.000000  \n",
      "75%         0.700000       0.000000  \n",
      "max         0.900000       1.000000  \n",
      "\n",
      "Missing Values:\n",
      "LoanID            0\n",
      "Age               0\n",
      "Income            0\n",
      "LoanAmount        0\n",
      "CreditScore       0\n",
      "MonthsEmployed    0\n",
      "NumCreditLines    0\n",
      "InterestRate      0\n",
      "LoanTerm          0\n",
      "DTIRatio          0\n",
      "Education         0\n",
      "EmploymentType    0\n",
      "MaritalStatus     0\n",
      "HasMortgage       0\n",
      "HasDependents     0\n",
      "LoanPurpose       0\n",
      "HasCoSigner       0\n",
      "Default           0\n",
      "dtype: int64\n",
      "\n",
      "Target Distribution:\n",
      "Default\n",
      "0    225694\n",
      "1     29653\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. EXPLORATORY DATA ANALYSIS\n",
    "def perform_eda(df):\n",
    "    \"\"\"Quick EDA without visualizations\"\"\"\n",
    "    print(\"=== EXPLORATORY DATA ANALYSIS ===\")\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nTarget Distribution:\")\n",
    "    print(df['Default'].value_counts())\n",
    "\n",
    "perform_eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8931861c-81ef-41e5-aa3e-60c4335dfda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FEATURE ENGINEERING ===\n",
      "Features: 20 | Records: 255347\n",
      "Saved label_encoders.pkl\n",
      "Saved feature_columns.pkl\n"
     ]
    }
   ],
   "source": [
    "# 4. FEATURE ENGINEERING\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Feature engineering and preprocessing\"\"\"\n",
    "    print(\"=== FEATURE ENGINEERING ===\")\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    df_processed['LoanToIncome'] = df_processed['LoanAmount'] / df_processed['Income']\n",
    "    df_processed['MonthlyPayment'] = (\n",
    "        (df_processed['LoanAmount'] *\n",
    "         (df_processed['InterestRate']/100/12) *\n",
    "         (1 + df_processed['InterestRate']/100/12)**df_processed['LoanTerm']) /\n",
    "        ((1 + df_processed['InterestRate']/100/12)**df_processed['LoanTerm'] - 1)\n",
    "    )\n",
    "    df_processed['PaymentToIncome'] = df_processed['MonthlyPayment'] / (df_processed['Income']/12)\n",
    "    df_processed['CreditUtilization'] = df_processed['LoanAmount'] / df_processed['CreditScore']\n",
    "    \n",
    "    categorical_cols = ['Education', 'EmploymentType', 'MaritalStatus', \n",
    "                        'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col + '_encoded'] = le.fit_transform(df_processed[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    feature_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', \n",
    "                    'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', \n",
    "                    'LoanToIncome', 'MonthlyPayment', 'PaymentToIncome', 'CreditUtilization'] + \\\n",
    "                   [col + '_encoded' for col in categorical_cols]\n",
    "    \n",
    "    X = df_processed[feature_cols]\n",
    "    y = df_processed['Default']\n",
    "    \n",
    "    print(f\"Features: {X.shape[1]} | Records: {X.shape[0]}\")\n",
    "    return X, y, df_processed, label_encoders\n",
    "\n",
    "X, y, df_processed, label_encoders = feature_engineering(df)\n",
    "\n",
    "joblib.dump(label_encoders, \"models/label_encoders.pkl\")\n",
    "print(\"Saved label_encoders.pkl\")\n",
    "\n",
    "joblib.dump(list(X.columns), \"models/feature_columns.pkl\")\n",
    "print(\"Saved feature_columns.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6039ce2e-b7bd-41dd-a7f1-244b0547d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed successfully!\n",
      "Scaler saved as scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# 5. DATA PREPROCESSING\n",
    "def preprocess_data(X, y):\n",
    "    \"\"\"Split and scale data\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Data preprocessed successfully!\")\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler = preprocess_data(X, y)\n",
    "\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "print(\"Scaler saved as scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418fc820-b0a7-460c-9f8f-fd906a6d0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression RESULTS ===\n",
      "AUC-ROC Score: 0.7594\n",
      "Confusion Matrix:\n",
      "[[46690 21019]\n",
      " [ 2731  6165]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.69      0.80     67709\n",
      "           1       0.23      0.69      0.34      8896\n",
      "\n",
      "    accuracy                           0.69     76605\n",
      "   macro avg       0.59      0.69      0.57     76605\n",
      "weighted avg       0.86      0.69      0.74     76605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/22 22:37:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved logistic_regression_model.pkl\n",
      "\n",
      "=== XGBoost RESULTS ===\n",
      "AUC-ROC Score: 0.7556\n",
      "Confusion Matrix:\n",
      "[[67273   436]\n",
      " [ 8263   633]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     67709\n",
      "           1       0.59      0.07      0.13      8896\n",
      "\n",
      "    accuracy                           0.89     76605\n",
      "   macro avg       0.74      0.53      0.53     76605\n",
      "weighted avg       0.86      0.89      0.84     76605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/22 22:37:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved xgboost_model.pkl\n",
      "[LightGBM] [Info] Number of positive: 20757, number of negative: 157985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2335\n",
      "[LightGBM] [Info] Number of data points in the train set: 178742, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "=== LightGBM RESULTS ===\n",
      "AUC-ROC Score: 0.7570\n",
      "Confusion Matrix:\n",
      "[[47586 20123]\n",
      " [ 2901  5995]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.81     67709\n",
      "           1       0.23      0.67      0.34      8896\n",
      "\n",
      "    accuracy                           0.70     76605\n",
      "   macro avg       0.59      0.69      0.57     76605\n",
      "weighted avg       0.86      0.70      0.75     76605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/22 22:38:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lightgbm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# 6. MODEL TRAINING AND EVALUATION (NO ROC CURVES)\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n=== {model_name} RESULTS ===\")\n",
    "    print(f\"AUC-ROC Score: {auc_roc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    return auc_roc\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Logistic Regression\n",
    "with mlflow.start_run(run_name=\"Logistic_Regression\"):\n",
    "    lr_model = LogisticRegression(random_state=42, class_weight=\"balanced\")\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    models['Logistic Regression'] = lr_model\n",
    "    auc = evaluate_model(lr_model, X_test, y_test, \"Logistic Regression\")\n",
    "    results['Logistic Regression'] = auc\n",
    "    mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.sklearn.log_model(lr_model, name=\"logistic_regression_model\")\n",
    "\n",
    "    joblib.dump(lr_model, \"models/logistic_regression_model.pkl\")\n",
    "    print(\"Saved logistic_regression_model.pkl\")\n",
    "\n",
    "# XGBoost\n",
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    xgb_model = xgb.XGBClassifier(random_state=42, n_estimators=100, max_depth=6, learning_rate=0.1, class_weight=\"balanced\")\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    models['XGBoost'] = xgb_model\n",
    "    auc = evaluate_model(xgb_model, X_test, y_test, \"XGBoost\")\n",
    "    results['XGBoost'] = auc\n",
    "    mlflow.log_param(\"model\", \"XGBoost\")\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.xgboost.log_model(xgb_model, name=\"xgboost_model\")\n",
    "\n",
    "    joblib.dump(xgb_model, \"models/xgboost_model.pkl\")\n",
    "    print(\"Saved xgboost_model.pkl\")\n",
    "\n",
    "# LightGBM\n",
    "with mlflow.start_run(run_name=\"LightGBM\"):\n",
    "    lgb_model = lgb.LGBMClassifier(random_state=42, n_estimators=100, max_depth=6, learning_rate=0.1, class_weight=\"balanced\")\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    models['LightGBM'] = lgb_model\n",
    "    auc = evaluate_model(lgb_model, X_test, y_test, \"LightGBM\")\n",
    "    results['LightGBM'] = auc\n",
    "    mlflow.log_param(\"model\", \"LightGBM\")\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    mlflow.lightgbm.log_model(lgb_model, name=\"lightgbm_model\")\n",
    "\n",
    "    joblib.dump(lgb_model, \"models/lightgbm_model.pkl\")\n",
    "    print(\"Saved lightgbm_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e0885c-5d14-4537-9c0d-8dcfd8847ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL COMPARISON ===\n",
      "                 Model   AUC-ROC\n",
      "0  Logistic Regression  0.759395\n",
      "2             LightGBM  0.757038\n",
      "1              XGBoost  0.755599\n"
     ]
    }
   ],
   "source": [
    "# 7. MODEL COMPARISON (TEXT ONLY)\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "model_comparison = pd.DataFrame({'Model': results.keys(), 'AUC-ROC': results.values()}).sort_values('AUC-ROC', ascending=False)\n",
    "print(model_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733a4247-aa1f-43fe-8ad3-2d2ca3073af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter LoanID to generate recommendations:  42SRSHU039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RECOMMENDATION FOR LoanID: 42SRSHU039 ===\n",
      "Default Probability: 89.24%\n",
      "Risk Level: High Risk\n",
      "Recommended Action: Escalate to collections, consider restructuring\n"
     ]
    }
   ],
   "source": [
    "# 9. RECOMMENDATIONS (INPUT BASED)\n",
    "def generate_recommendations(model, scaler, sample_data):\n",
    "    \"\"\"Generate risk-based recovery recommendations\"\"\"\n",
    "    scaled = scaler.transform(sample_data.reshape(1, -1))\n",
    "    prob = model.predict_proba(scaled)[0, 1]\n",
    "    if prob < 0.3:\n",
    "        level, action = \"Low Risk\", \"Monitor regularly\"\n",
    "    elif prob < 0.7:\n",
    "        level, action = \"Medium Risk\", \"Contact borrower, offer payment plan options\"\n",
    "    else:\n",
    "        level, action = \"High Risk\", \"Escalate to collections, consider restructuring\"\n",
    "    return prob, level, action\n",
    "\n",
    "def get_recommendations_by_loanid(df, X, model, scaler):\n",
    "    \"\"\"Ask user for LoanID and generate recommendations\"\"\"\n",
    "    loan_id = input(\"\\nEnter LoanID to generate recommendations: \").strip()\n",
    "    if loan_id not in df['LoanID'].astype(str).values:\n",
    "        print(\"LoanID not found.\")\n",
    "        return\n",
    "    idx = df[df['LoanID'].astype(str) == loan_id].index[0]\n",
    "    data = X.iloc[idx].values\n",
    "    prob, level, action = generate_recommendations(model, scaler, data)\n",
    "    print(f\"\\n=== RECOMMENDATION FOR LoanID: {loan_id} ===\")\n",
    "    print(f\"Default Probability: {prob:.2%}\")\n",
    "    print(f\"Risk Level: {level}\")\n",
    "    print(f\"Recommended Action: {action}\")\n",
    "\n",
    "best_model = models[model_comparison.iloc[0]['Model']]\n",
    "get_recommendations_by_loanid(df, X, best_model, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00a32c9-24d6-4e77-94de-448c5f0e5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model, scaler, encoders, and feature list successfully!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Age:  24\n",
      "Annual Income:  120000\n",
      "Loan Amount:  400000\n",
      "Credit Score:  300\n",
      "Months Employed:  10\n",
      "Number of Credit Lines:  3\n",
      "Interest Rate (%):  15\n",
      "Loan Term (months):  60\n",
      "Debt-to-Income Ratio:  0.8\n",
      "Education (Bachelor's/Master's/etc):  Bachelor's\n",
      "Employment Type (Full-time/Part-time/etc):  Full-time\n",
      "Marital Status (Married/Single/etc):  Married\n",
      "Has Mortgage (Yes/No):  Yes\n",
      "Has Dependents (Yes/No):  Yes\n",
      "Loan Purpose (Home/Other/etc):  Other\n",
      "Has Co-Signer (Yes/No):  No\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL PREDICTION ====\n",
      "Default Probability: 0.8135\n",
      "ðŸ”´ HIGH DEFAULT RISK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# ---- Load model & preprocessing artifacts ----\n",
    "model = joblib.load(\"models/logistic_regression_model.pkl\")\n",
    "scaler = joblib.load(\"models/scaler.pkl\")\n",
    "label_encoders = joblib.load(\"models/label_encoders.pkl\")\n",
    "feature_columns = joblib.load(\"models/feature_columns.pkl\")\n",
    "\n",
    "print(\"Loaded model, scaler, encoders, and feature list successfully!\")\n",
    "\n",
    "# ---- Collect ALL user inputs ----\n",
    "data = {}\n",
    "\n",
    "data[\"Age\"] = int(input(\"Age: \"))\n",
    "data[\"Income\"] = float(input(\"Annual Income: \"))\n",
    "data[\"LoanAmount\"] = float(input(\"Loan Amount: \"))\n",
    "data[\"CreditScore\"] = float(input(\"Credit Score: \"))\n",
    "data[\"MonthsEmployed\"] = int(input(\"Months Employed: \"))\n",
    "data[\"NumCreditLines\"] = int(input(\"Number of Credit Lines: \"))\n",
    "data[\"InterestRate\"] = float(input(\"Interest Rate (%): \"))\n",
    "data[\"LoanTerm\"] = int(input(\"Loan Term (months): \"))\n",
    "data[\"DTIRatio\"] = float(input(\"Debt-to-Income Ratio: \"))\n",
    "\n",
    "# ---- Categorical Inputs ----\n",
    "data[\"Education\"] = input(\"Education (Bachelor's/Master's/etc): \")\n",
    "data[\"EmploymentType\"] = input(\"Employment Type (Full-time/Part-time/etc): \")\n",
    "data[\"MaritalStatus\"] = input(\"Marital Status (Married/Single/etc): \")\n",
    "data[\"HasMortgage\"] = input(\"Has Mortgage (Yes/No): \")\n",
    "data[\"HasDependents\"] = input(\"Has Dependents (Yes/No): \")\n",
    "data[\"LoanPurpose\"] = input(\"Loan Purpose (Home/Other/etc): \")\n",
    "data[\"HasCoSigner\"] = input(\"Has Co-Signer (Yes/No): \")\n",
    "\n",
    "df_input = pd.DataFrame([data])\n",
    "\n",
    "# ---- Feature Engineering (Same as Training) ----\n",
    "df_input[\"LoanToIncome\"] = df_input[\"LoanAmount\"] / df_input[\"Income\"]\n",
    "\n",
    "df_input[\"MonthlyPayment\"] = (\n",
    "    (df_input[\"LoanAmount\"] * \n",
    "     (df_input[\"InterestRate\"] / 100 / 12) *\n",
    "     (1 + df_input[\"InterestRate\"] / 100 / 12) ** df_input[\"LoanTerm\"]) /\n",
    "    ((1 + df_input[\"InterestRate\"] / 100 / 12) ** df_input[\"LoanTerm\"] - 1)\n",
    ")\n",
    "\n",
    "df_input[\"PaymentToIncome\"] = df_input[\"MonthlyPayment\"] / (df_input[\"Income\"] / 12)\n",
    "df_input[\"CreditUtilization\"] = df_input[\"LoanAmount\"] / df_input[\"CreditScore\"]\n",
    "\n",
    "# ---- Apply Label Encoding ----\n",
    "for col, encoder in label_encoders.items():\n",
    "    df_input[col + \"_encoded\"] = encoder.transform(df_input[col])\n",
    "\n",
    "# ---- Build full input frame with ALL features ----\n",
    "final_input = pd.DataFrame(columns=feature_columns)\n",
    "final_input.loc[0] = 0\n",
    "final_input.update(df_input)\n",
    "\n",
    "# ---- Scale input ----\n",
    "scaled_input = scaler.transform(final_input)\n",
    "\n",
    "# ---- Predict ----\n",
    "pred = model.predict(scaled_input)[0]\n",
    "prob = model.predict_proba(scaled_input)[0][1]\n",
    "\n",
    "# ---- Result ----\n",
    "print(\"\\n==== FINAL PREDICTION ====\")\n",
    "print(\"Default Probability:\", round(prob, 4))\n",
    "\n",
    "if pred == 1:\n",
    "    print(\"ðŸ”´ HIGH DEFAULT RISK\")\n",
    "else:\n",
    "    print(\"ðŸŸ¢ LOW DEFAULT RISK\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
